{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install lightgbm optuna scikit-learn pandas matplotlib seaborn IProgress jupyter ipywidgets -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install ../../target/wheels/perpetual-1.0.0-cp313-cp313-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "from time import process_time, time\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from perpetual import PerpetualBooster\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold, cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"lead_scoring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.pop(\"Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "X[object_cols] = X[object_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rename(\n",
    "    columns={\n",
    "        \"What is your current occupation\": \"Occupation\",\n",
    "        \"Through Recommendations\": \"Recommendation\",\n",
    "        \"A free copy of Mastering The Interview\": \"Free Copy\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"Prospect ID\",\n",
    "    \"Lead Number\",\n",
    "    \"How did you hear about X Education\",\n",
    "    \"Lead Profile\",\n",
    "    \"Lead Quality\",\n",
    "    \"Asymmetrique Profile Score\",\n",
    "    \"Asymmetrique Activity Score\",\n",
    "    \"Asymmetrique Activity Index\",\n",
    "    \"Asymmetrique Profile Index\",\n",
    "    \"Tags\",\n",
    "    \"Last Notable Activity\",\n",
    "]\n",
    "cols_to_drop += [\n",
    "    \"I agree to pay the amount through cheque\",\n",
    "    \"Get updates on DM Content\",\n",
    "    \"Update me on Supply Chain Content\",\n",
    "    \"Receive More Updates About Our Courses\",\n",
    "    \"Magazine\",\n",
    "]\n",
    "cols_to_drop += [\"What matters most to you in choosing a course\", \"Country\", \"City\"]\n",
    "cols_to_drop += [\n",
    "    \"Do Not Call\",\n",
    "    \"Search\",\n",
    "    \"Newspaper\",\n",
    "    \"Newspaper Article\",\n",
    "    \"Digital Advertisement\",\n",
    "    \"X Education Forums\",\n",
    "    \"Free Copy\",\n",
    "    \"Recommendation\",\n",
    "]\n",
    "\n",
    "X.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seed):\n",
    "    scoring = \"neg_log_loss\"\n",
    "    metric_function = log_loss\n",
    "    metric_name = \"log_loss\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.6, random_state=seed\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        scoring,\n",
    "        metric_function,\n",
    "        metric_name,\n",
    "    )\n",
    "\n",
    "\n",
    "def objective_function(trial, seed, n_estimators, X_train, y_train, scoring, cv):\n",
    "    params = {\n",
    "        \"seed\": seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5, log=True),\n",
    "        \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 1e-6, 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-6, 1.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-6, 1.0, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 33),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 1024),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 100),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(\"models\", cv_results[\"estimator\"])\n",
    "\n",
    "    return -1 * np.mean(cv_results[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n_trials = 100\n",
    "n_estimators = 100\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    scoring,\n",
    "    metric_function,\n",
    "    metric_name,\n",
    ") = prepare_data(seed)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "obj = partial(\n",
    "    objective_function,\n",
    "    seed=seed,\n",
    "    n_estimators=n_estimators,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    ")\n",
    "\n",
    "start = process_time()\n",
    "tick = time()\n",
    "study.optimize(obj, n_trials=n_trials)\n",
    "stop = process_time()\n",
    "\n",
    "\n",
    "print(f\"seed: {seed}, cpu time: {stop - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "\n",
    "params = study.best_trial.params\n",
    "params[\"n_estimators\"] = n_estimators\n",
    "params[\"seed\"] = seed\n",
    "params[\"verbosity\"] = -1\n",
    "lgbm = LGBMClassifier(**params)\n",
    "lgbm_isotonic = CalibratedClassifierCV(\n",
    "    LGBMClassifier(**params), cv=cv, method=\"isotonic\"\n",
    ")\n",
    "lgbm_sigmoid = CalibratedClassifierCV(LGBMClassifier(**params), cv=cv, method=\"sigmoid\")\n",
    "\n",
    "lgbm_models = [\n",
    "    (lgbm, \"LightGBM\"),\n",
    "    (lgbm_isotonic, \"LightGBM + Isotonic\"),\n",
    "    (lgbm_sigmoid, \"LightGBM + Sigmoid\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "def expected_calibration_error(\n",
    "    y_true: Union[np.ndarray, Sequence[int]],\n",
    "    y_pred: Union[np.ndarray, Sequence[float]],\n",
    "    n_bins: int = 10,\n",
    ") -> Tuple[float, np.ndarray, np.ndarray]:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    N = len(y_true)\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=n_bins)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    counts, _ = np.histogram(y_pred, bins=bins, range=(0.0, 1.0))\n",
    "    non_empty_counts = counts[counts > 0]\n",
    "    weights = non_empty_counts / N\n",
    "    ece = np.sum(weights * np.abs(prob_true - prob_pred))\n",
    "\n",
    "    return ece, prob_true, prob_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = GridSpec(4, 2)\n",
    "colors = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "for i, (clf, name) in enumerate(lgbm_models):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "    display = CalibrationDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        n_bins=n_bins,\n",
    "        name=name,\n",
    "        ax=ax_calibration_curve,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    calibration_displays[name] = display\n",
    "\n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots (Naive Bayes)\")\n",
    "\n",
    "# Add histogram\n",
    "grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1)]\n",
    "for i, (_, name) in enumerate(lgbm_models):\n",
    "    row, col = grid_positions[i]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "    ax.hist(\n",
    "        calibration_displays[name].y_prob,\n",
    "        range=(0, 1),\n",
    "        bins=n_bins,\n",
    "        label=name,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    expected_calibration_error(\n",
    "        y_test, lgbm_models[0][0].predict_proba(X_test)[:, 1], n_bins\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    expected_calibration_error(\n",
    "        y_test, lgbm_models[1][0].predict_proba(X_test)[:, 1], n_bins\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    expected_calibration_error(\n",
    "        y_test, lgbm_models[2][0].predict_proba(X_test)[:, 1], n_bins\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_cal_classifiers = lgbm_models[1][0].calibrated_classifiers_\n",
    "print(type(lgbm_cal_classifiers[0]))\n",
    "print(len(lgbm_cal_classifiers))\n",
    "print([d for d in dir(lgbm_cal_classifiers[0]) if not d.startswith(\"__\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_objective(\n",
    "    ground_truth,\n",
    "    predicted_probs,\n",
    "    threshold,\n",
    "    value_per_lead=100,\n",
    "    cost_per_false_positive=20,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Business objective function to optimize lead scoring threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - predicted_probs: array-like of predicted probabilities (floats between 0 and 1)\n",
    "    - ground_truth: array-like of true labels (0 or 1)\n",
    "    - threshold: float, decision threshold for classifying leads\n",
    "    - value_per_lead: monetary value of a true positive lead\n",
    "    - cost_per_false_positive: cost incurred for pursuing a false positive lead\n",
    "\n",
    "    Returns:\n",
    "    - net_gain: total business value (profit) from applying the threshold\n",
    "    \"\"\"\n",
    "    predicted_labels = (np.array(predicted_probs) >= threshold).astype(int)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "\n",
    "    true_positives = np.sum((predicted_labels == 1) & (ground_truth == 1))\n",
    "    false_positives = np.sum((predicted_labels == 1) & (ground_truth == 0))\n",
    "\n",
    "    net_gain = (true_positives * value_per_lead) - (\n",
    "        false_positives * cost_per_false_positive\n",
    "    )\n",
    "\n",
    "    return net_gain, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_dummy = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    ")\n",
    "y_pred_dummy = np.array(\n",
    "    [\n",
    "        0.1,\n",
    "        0.4,\n",
    "        0.3,\n",
    "        0.8,\n",
    "        0.7,\n",
    "        0.1,\n",
    "        0.2,\n",
    "        0.9,\n",
    "        0.3,\n",
    "        0.1,\n",
    "        0.6,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.6,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.4,\n",
    "    ]\n",
    ")\n",
    "print(len(y_true_dummy))\n",
    "print(len(y_pred_dummy))\n",
    "print(y_true_dummy[y_pred_dummy < 0.5])\n",
    "print(len(y_true_dummy[y_pred_dummy < 0.5]))\n",
    "print(business_objective(y_true_dummy, y_pred_dummy, threshold=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    business_objective(\n",
    "        y_test.values, lgbm_models[0][0].predict_proba(X_test)[:, 1], threshold=0.5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.01, 1.0, 0.01):\n",
    "    profit, margin = business_objective(\n",
    "        y_test.values, lgbm_models[1][0].predict_proba(X_test)[:, 1], threshold=t\n",
    "    )\n",
    "    print(f\"Threshold: {t:.2f}, Profit: {profit:.0f}, Margin: {margin:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "\n",
    "plot_importance(lgbm_models[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "y_proba_lgbm = np.mean(\n",
    "    [m.predict_proba(X_test)[:, 1] for m in lgbm_cal_classifiers], axis=0\n",
    ")\n",
    "\n",
    "print(accuracy_score(y_test, np.rint(y_proba_lgbm)))\n",
    "print(f1_score(y_test, np.rint(y_proba_lgbm)))\n",
    "print(roc_auc_score(y_test, y_proba_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_nodes(perp: PerpetualBooster):\n",
    "    return [\n",
    "        {node.num: node for node in tree_nodes if node.is_leaf}\n",
    "        for tree_nodes in perp.get_node_lists()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(leaf_nodes, pred_nodes):\n",
    "    pred_weights = np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    leaf_nodes[i][key].weights\n",
    "                    for key in leaf_nodes[i].keys() & set(nodes)\n",
    "                ][0]\n",
    "                for nodes in tree_nodes\n",
    "            ]\n",
    "            for i, tree_nodes in enumerate(pred_nodes)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return np.sort(pred_weights, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Perpetual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_models = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(f\"Fold {i}\")\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "    perp = PerpetualBooster(budget=1.0, iteration_limit=10000)\n",
    "    perp.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    print(f\"Number of trees: {perp.number_of_trees}\")\n",
    "\n",
    "    perp_models.append(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "y_proba_perp = np.mean([m.predict_proba(X_test)[:, 1] for m in perp_models], axis=0)\n",
    "\n",
    "print(accuracy_score(y_test, np.rint(y_proba_perp)))\n",
    "print(f1_score(y_test, np.rint(y_proba_perp)))\n",
    "print(roc_auc_score(y_test, y_proba_perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights = get_weights(get_leaf_nodes(perp), perp.predict_nodes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights = get_weights(get_leaf_nodes(perp), perp.predict_nodes(X_test))\n",
    "pred_lower = np.sum(np.min(pred_weights, axis=2), axis=0) + perp.base_score\n",
    "pred_lower = 1.0 / (1.0 + np.exp(-pred_lower))\n",
    "pred_lower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights = get_weights(get_leaf_nodes(perp), perp.predict_nodes(X_test))\n",
    "pred_upper = np.sum(np.max(pred_weights, axis=2), axis=0) + perp.base_score\n",
    "pred_upper = 1.0 / (1.0 + np.exp(-pred_upper))\n",
    "pred_upper.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(pred_upper - pred_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(pred_lower, pred_upper, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(pred_upper - pred_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(\n",
    "    low=0, high=5, size=(pred_weights.shape[0], pred_weights.shape[1], n_simulations)\n",
    ")\n",
    "new_pred_weights = np.take_along_axis(pred_weights, indices, axis=2)\n",
    "print(f\"New array shape: {new_pred_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_weights_sum = np.sum(new_pred_weights, axis=0) + perp.base_score\n",
    "new_pred_weights_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_pred_weights_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_weights_sum_proba = 1.0 / (1.0 + np.exp(-new_pred_weights_sum))\n",
    "new_pred_weights_sum_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_pred_weights_sum_proba[1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    np.max(new_pred_weights_sum_proba, axis=1)\n",
    "    - np.min(new_pred_weights_sum_proba, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_weights_sum_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_sim(m_sim, X_sim, n_sim=100):\n",
    "    pred_weights_sim = get_weights(get_leaf_nodes(m_sim), m_sim.predict_nodes(X_sim))\n",
    "    indices_sim = np.random.randint(\n",
    "        low=0,\n",
    "        high=5,\n",
    "        size=(pred_weights_sim.shape[0], pred_weights_sim.shape[1], n_sim),\n",
    "    )\n",
    "    new_pred_weights_sim = np.take_along_axis(pred_weights_sim, indices_sim, axis=2)\n",
    "    new_pred_weights_sum_sim = np.sum(new_pred_weights_sim, axis=0) + m_sim.base_score\n",
    "    new_pred_weights_sum_proba_sim = 1.0 / (1.0 + np.exp(-new_pred_weights_sum_sim))\n",
    "\n",
    "    return new_pred_weights_sum_proba_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_t(trial):\n",
    "    t = trial.suggest_float(\"threshold\", 0.0, 0.3)\n",
    "\n",
    "    profits = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        _X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        _y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        y_pred_sim = get_proba_sim(perp_models[i], X_test_cv, n_simulations)\n",
    "\n",
    "        profits_fold = []\n",
    "        for j in range(n_simulations):\n",
    "            profit, margin = business_objective(\n",
    "                y_test_cv.values, y_pred_sim[:, j], threshold=t\n",
    "            )\n",
    "            profits_fold.append(profit)\n",
    "\n",
    "    profits.append(profits_fold)\n",
    "\n",
    "    return np.mean(np.array(profits).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_t = optuna.samplers.TPESampler(seed=seed)\n",
    "study_t = optuna.create_study(direction=\"maximize\", sampler=sampler_t)\n",
    "study_t.optimize(objective_t, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_t.best_trial.params[\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean([m.predict_proba(X_test)[:, 1] for m in perp_models], axis=0)\n",
    "profit, margin = business_objective(\n",
    "    y_test.values, y_proba, threshold=study_t.best_trial.params[\"threshold\"]\n",
    ")\n",
    "print(f\"Profit: {profit}, Margin: {margin}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "# Optimize threshold and weight index together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_weights = []\n",
    "for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "    pred_weights = get_weights(\n",
    "        get_leaf_nodes(perp_models[i]), perp_models[i].predict_nodes(X_test_cv)\n",
    "    )\n",
    "    model_pred_weights.append(pred_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_from_weights(p_weights, w, b_score):\n",
    "    cal_weight, w_i_lower = math.modf(w)\n",
    "    w_i_lower = int(w_i_lower)\n",
    "    w_i_upper = w_i_lower + 1\n",
    "\n",
    "    weights_lower = np.sum(p_weights[:, :, w_i_lower], axis=0) + b_score\n",
    "    weights_upper = np.sum(p_weights[:, :, w_i_upper], axis=0) + b_score\n",
    "\n",
    "    weighted = weights_lower * (1 - cal_weight) + weights_upper * cal_weight\n",
    "\n",
    "    y_proba = 1.0 / (1.0 + np.exp(-weighted))\n",
    "\n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_w(trial):\n",
    "    t = trial.suggest_float(\"threshold\", 0.0, 0.3)\n",
    "    w = trial.suggest_float(\"weight_index\", 0.0, 4.0)\n",
    "\n",
    "    profits = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        _X_train_cv, _X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        _y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        y_proba = get_proba_from_weights(\n",
    "            model_pred_weights[i], w, perp_models[i].base_score\n",
    "        )\n",
    "\n",
    "        profit, margin = business_objective(\n",
    "            y_test_cv.values, y_proba, threshold=t, verbose=False\n",
    "        )\n",
    "\n",
    "    profits.append(profit)\n",
    "\n",
    "    return np.mean(profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_w = optuna.samplers.TPESampler(seed=seed)\n",
    "study_w = optuna.create_study(direction=\"maximize\", sampler=sampler_w)\n",
    "study_w.optimize(objective_w, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_w.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean(\n",
    "    [\n",
    "        get_proba_from_weights(\n",
    "            get_weights(get_leaf_nodes(m), m.predict_nodes(X_test)),\n",
    "            study_w.best_trial.params[\"weight_index\"],\n",
    "            m.base_score,\n",
    "        )\n",
    "        for m in perp_models\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "profit_w, margin_w = business_objective(\n",
    "    y_test.values,\n",
    "    y_proba,\n",
    "    threshold=study_w.best_trial.params[\"threshold\"],\n",
    "    verbose=False,\n",
    ")\n",
    "print(f\"Profit: {profit_w}, Margin: {margin_w}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# Optimize business objective with calibrated LightGBM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0\n",
    "best_profit = 0\n",
    "\n",
    "for t in np.arange(0.01, 0.5, 0.01):\n",
    "    profits = []\n",
    "    margins = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        m = lgbm_cal_classifiers[i]\n",
    "        y_proba = m.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "        profit, margin = business_objective(\n",
    "            y_test_cv.values, y_proba, threshold=t, verbose=False\n",
    "        )\n",
    "        profits.append(profit)\n",
    "        margins.append(margin)\n",
    "\n",
    "    if np.mean(profits) > best_profit:\n",
    "        best_profit = np.mean(profits)\n",
    "        best_threshold = t\n",
    "\n",
    "    print(\n",
    "        f\"Threshold: {t:.3f}, Profit: {np.mean(profits):.0f}, Margin: {np.mean(margins):.2f}%\"\n",
    "    )\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.3f}, Best profit: {best_profit:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean([m.predict_proba(X_test)[:, 1] for m in lgbm_cal_classifiers], axis=0)\n",
    "profit_l, margin_l = business_objective(\n",
    "    y_test.values, y_proba, threshold=best_threshold, verbose=False\n",
    ")\n",
    "print(f\"Profit: {profit_l}, Margin: {margin_l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((profit_w - profit_l) / abs(profit_l)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "# Optimize threshold, weight index, budget together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_list = [1.0, 1.5, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_models = []\n",
    "model_pred_weights = []\n",
    "for budget in budget_list:\n",
    "    cv_pred_weights = []\n",
    "    p_models_cv = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "        m = PerpetualBooster(budget=budget, iteration_limit=10000)\n",
    "        m.fit(X_train_cv, y_train_cv)\n",
    "        pred_weights = get_weights(get_leaf_nodes(m), m.predict_nodes(X_test_cv))\n",
    "        cv_pred_weights.append(pred_weights)\n",
    "        p_models_cv.append(m)\n",
    "        print(f\"Budget: {budget}, Fold: {i}, Number of trees: {m.number_of_trees}\")\n",
    "    print()\n",
    "    p_models.append(p_models_cv)\n",
    "    model_pred_weights.append(cv_pred_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_index_min = 0\n",
    "for i, b in enumerate(budget_list):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    cv_models_prev = p_models[i - 1]\n",
    "    cv_models = p_models[i]\n",
    "    min_diff_n_trees = min(\n",
    "        [\n",
    "            cv_models[j].number_of_trees - cv_models_prev[j].number_of_trees\n",
    "            for j in range(len(cv_models))\n",
    "        ]\n",
    "    )\n",
    "    if min_diff_n_trees < 0:\n",
    "        budget_index_min = i\n",
    "    print(\n",
    "        f\"i: {i}, budget: {b}, previous budget n_trees: {[cv_models_prev[j].number_of_trees for j in range(len(cv_models_prev))]}, current budget n_trees: {[cv_models[j].number_of_trees for j in range(len(cv_models))]}, min_diff_n_trees: {min_diff_n_trees}\"\n",
    "    )\n",
    "\n",
    "print(f\"Minimum budget index without tree count regression: {budget_index_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_b(trial):\n",
    "    t = trial.suggest_float(\"threshold\", 0.0, 0.3)\n",
    "    w = trial.suggest_float(\"weight_index\", 0.0, 4.0)\n",
    "    b = trial.suggest_int(\"budget_index\", budget_index_min, len(budget_list) - 1)\n",
    "\n",
    "    profits = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        _X_train_cv, _X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        _y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        y_proba = get_proba_from_weights(\n",
    "            model_pred_weights[b][i], w, p_models[b][i].base_score\n",
    "        )\n",
    "\n",
    "        profit, margin = business_objective(\n",
    "            y_test_cv.values, y_proba, threshold=t, verbose=False\n",
    "        )\n",
    "\n",
    "    profits.append(profit)\n",
    "\n",
    "    return np.mean(profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_b = optuna.samplers.TPESampler(seed=seed)\n",
    "study_b = optuna.create_study(direction=\"maximize\", sampler=sampler_b)\n",
    "study_b.optimize(objective_b, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_b.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_list[study_b.best_trial.params[\"budget_index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean(\n",
    "    [\n",
    "        get_proba_from_weights(\n",
    "            get_weights(get_leaf_nodes(m), m.predict_nodes(X_test)),\n",
    "            study_b.best_trial.params[\"weight_index\"],\n",
    "            m.base_score,\n",
    "        )\n",
    "        for m in p_models[study_b.best_trial.params[\"budget_index\"]]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "profit_b, margin_b = business_objective(\n",
    "    y_test.values,\n",
    "    y_proba,\n",
    "    threshold=study_b.best_trial.params[\"threshold\"],\n",
    "    verbose=False,\n",
    ")\n",
    "print(f\"Profit: {profit_b}, Margin: {margin_b}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((profit_b - profit_l) / abs(profit_l)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM n_estimators = 100\n",
    "# 0.1 -> 1010250 -> -4.05428401259253\n",
    "# 0.2 -> 989250  -> -2.7184548625882754\n",
    "# 0.3 -> 987000  -> -8.580787883944526\n",
    "# 0.5 -> 1135000 -> -4.479707308772228\n",
    "# 1.0 -> 1046250 -> -0.22547434697524038\n",
    "# 1.5 -> 1052000 -> 1.3060495192716752\n",
    "# 2.0 -> 1073500 -> 1.9016421339232537\n",
    "# 2.5 -> 1072500 -> -0.6041010805751723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM n_estimators = 1000\n",
    "# 2.0 -> 1074250 -> 1.131326776140825"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forust-main-perp-oss (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
