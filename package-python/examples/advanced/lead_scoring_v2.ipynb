{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install lightgbm optuna scikit-learn pandas matplotlib seaborn IProgress jupyter ipywidgets -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install ../../target/wheels/perpetual-1.0.0-cp313-cp313-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "from time import process_time, time\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from perpetual import PerpetualBooster\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    X = data.drop(\"y\", axis=1)\n",
    "    y = data.y.apply(lambda x: 1 if x == \"yes\" else 0)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive.ics.uci.edu/dataset/222/bank+marketing\n",
    "\n",
    "X_train, y_train = get_data(\"train_v2.csv\")\n",
    "X_test, y_test = get_data(\"test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "X_train[object_cols] = X_train[object_cols].astype(\"category\")\n",
    "object_cols = X_test.select_dtypes(include=[\"object\"]).columns\n",
    "X_test[object_cols] = X_test[object_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_train.values))\n",
    "print(y_train.value_counts())\n",
    "print(np.mean(y_test.values))\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seed):\n",
    "    scoring = \"neg_log_loss\"\n",
    "    metric_function = log_loss\n",
    "    metric_name = \"log_loss\"\n",
    "\n",
    "    return (\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        scoring,\n",
    "        metric_function,\n",
    "        metric_name,\n",
    "    )\n",
    "\n",
    "\n",
    "def objective_function(trial, seed, n_estimators, X_train, y_train, scoring, cv):\n",
    "    params = {\n",
    "        \"seed\": seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5, log=True),\n",
    "        \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 1e-6, 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-6, 1.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-6, 1.0, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 33),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 1024),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 100),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        return_estimator=True,\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(\"models\", cv_results[\"estimator\"])\n",
    "\n",
    "    return -1 * np.mean(cv_results[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n_trials = 100\n",
    "n_estimators = 100\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    scoring,\n",
    "    metric_function,\n",
    "    metric_name,\n",
    ") = prepare_data(seed)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "obj = partial(\n",
    "    objective_function,\n",
    "    seed=seed,\n",
    "    n_estimators=n_estimators,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    ")\n",
    "\n",
    "start = process_time()\n",
    "tick = time()\n",
    "study.optimize(obj, n_trials=n_trials)\n",
    "stop = process_time()\n",
    "\n",
    "\n",
    "print(f\"seed: {seed}, cpu time: {stop - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "\n",
    "params = study.best_trial.params\n",
    "params[\"n_estimators\"] = n_estimators\n",
    "params[\"seed\"] = seed\n",
    "params[\"verbosity\"] = -1\n",
    "lgbm = LGBMClassifier(**params)\n",
    "lgbm_isotonic = CalibratedClassifierCV(\n",
    "    LGBMClassifier(**params), cv=cv, method=\"isotonic\"\n",
    ")\n",
    "lgbm_sigmoid = CalibratedClassifierCV(LGBMClassifier(**params), cv=cv, method=\"sigmoid\")\n",
    "\n",
    "lgbm_models = [\n",
    "    (lgbm, \"LightGBM\"),\n",
    "    (lgbm_isotonic, \"LightGBM + Isotonic\"),\n",
    "    (lgbm_sigmoid, \"LightGBM + Sigmoid\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "def expected_calibration_error(\n",
    "    y_true: Union[np.ndarray, Sequence[int]],\n",
    "    y_pred: Union[np.ndarray, Sequence[float]],\n",
    "    n_bins: int = 10,\n",
    ") -> Tuple[float, np.ndarray, np.ndarray]:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    N = len(y_true)\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=n_bins)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    counts, _ = np.histogram(y_pred, bins=bins, range=(0.0, 1.0))\n",
    "    non_empty_counts = counts[counts > 0]\n",
    "    weights = non_empty_counts / N\n",
    "    ece = np.sum(weights * np.abs(prob_true - prob_pred))\n",
    "\n",
    "    return ece, prob_true, prob_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = GridSpec(4, 2)\n",
    "colors = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "for i, (clf, name) in enumerate(lgbm_models):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "    display = CalibrationDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        n_bins=n_bins,\n",
    "        name=name,\n",
    "        ax=ax_calibration_curve,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    calibration_displays[name] = display\n",
    "\n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots (Naive Bayes)\")\n",
    "\n",
    "# Add histogram\n",
    "grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1)]\n",
    "for i, (_, name) in enumerate(lgbm_models):\n",
    "    row, col = grid_positions[i]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "    ax.hist(\n",
    "        calibration_displays[name].y_prob,\n",
    "        range=(0, 1),\n",
    "        bins=n_bins,\n",
    "        label=name,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    expected_calibration_error(\n",
    "        y_test, lgbm_models[0][0].predict_proba(X_test)[:, 1], n_bins\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    expected_calibration_error(\n",
    "        y_test, lgbm_models[1][0].predict_proba(X_test)[:, 1], n_bins\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    expected_calibration_error(\n",
    "        y_test, lgbm_models[2][0].predict_proba(X_test)[:, 1], n_bins\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_cal_classifiers = lgbm_models[1][0].calibrated_classifiers_\n",
    "print(type(lgbm_cal_classifiers[0]))\n",
    "print(len(lgbm_cal_classifiers))\n",
    "print([d for d in dir(lgbm_cal_classifiers[0]) if not d.startswith(\"__\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def business_objective(\n",
    "    y_true, y_proba, threshold, benefit_tp=1000, cost_fp=100, cost_fn=500, verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the net business value (profit) for a lead scoring model\n",
    "    at a given probability threshold.\n",
    "\n",
    "    This objective function quantifies the financial impact of the model's\n",
    "    classification decisions, maximizing:\n",
    "    (TP * Benefit_TP) - (FP * Cost_FP) - (FN * Cost_FN)\n",
    "\n",
    "    Inputs:\n",
    "    - y_true (np.array): Ground truth labels (0 for bad lead, 1 for good lead).\n",
    "    - y_proba (np.array): Predicted probabilities for the positive class (1).\n",
    "    - threshold (float): The probability cutoff (e.g., 0.5) used to classify leads.\n",
    "    - benefit_tp (float): Financial gain from a successful conversion (True Positive).\n",
    "    - cost_fp (float): Financial cost of sales time wasted on a dead lead (False Positive).\n",
    "    - cost_fn (float): Opportunity cost of a missed good lead (False Negative).\n",
    "\n",
    "    Returns:\n",
    "    - float: The total net business value achieved at this threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Classify leads based on the threshold\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # 2. Calculate the Confusion Matrix\n",
    "    # cm format: [[TN, FP], [FN, TP]]\n",
    "    # Ensure all inputs are NumPy arrays for safety\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # Use try/except for robust matrix calculation\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    except ValueError:\n",
    "        # Handle cases where the confusion matrix might have missing classes\n",
    "        # This is rare but good for robustness.\n",
    "        print(\n",
    "            \"Error: Could not unpack confusion matrix. Check unique values in y_true and y_pred.\"\n",
    "        )\n",
    "        return -np.inf  # Return negative infinity to indicate a bad result\n",
    "\n",
    "    # 3. Calculate the Net Business Value (The Objective Function)\n",
    "\n",
    "    # Value from True Positives (Successful Conversions)\n",
    "    value_tp = tp * benefit_tp\n",
    "\n",
    "    # Cost from False Positives (Wasted Sales Effort)\n",
    "    cost_fp_total = fp * cost_fp\n",
    "\n",
    "    # Cost from False Negatives (Lost Opportunity/Revenue)\n",
    "    cost_fn_total = fn * cost_fn\n",
    "\n",
    "    net_business_value = value_tp - cost_fp_total - cost_fn_total\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"--- Results for Threshold: {threshold:.4f} ---\")\n",
    "        print(f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\")\n",
    "        print(\n",
    "            f\"TP Value: ${value_tp:,.2f} | FP Cost: ${cost_fp_total:,.2f} | FN Cost: ${cost_fn_total:,.2f}\"\n",
    "        )\n",
    "        print(f\"Net Business Value: ${net_business_value:,.2f}\")\n",
    "        print(\"---------------------------------------\")\n",
    "\n",
    "    return net_business_value, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    business_objective(\n",
    "        y_test.values, lgbm_models[0][0].predict_proba(X_test)[:, 1], threshold=0.5\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.01, 1.0, 0.01):\n",
    "    profit, margin = business_objective(\n",
    "        y_test.values, lgbm_models[1][0].predict_proba(X_test)[:, 1], threshold=t\n",
    "    )\n",
    "    print(f\"Threshold: {t:.2f}, Profit: {profit:.0f}, Margin: {margin:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "\n",
    "plot_importance(lgbm_models[0][0], importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "y_proba_lgbm = np.mean(\n",
    "    [m.predict_proba(X_test)[:, 1] for m in lgbm_cal_classifiers], axis=0\n",
    ")\n",
    "\n",
    "print(accuracy_score(y_test, np.rint(y_proba_lgbm)))\n",
    "print(f1_score(y_test, np.rint(y_proba_lgbm)))\n",
    "print(roc_auc_score(y_test, y_proba_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_nodes(perp: PerpetualBooster):\n",
    "    return [\n",
    "        {node.num: node for node in tree_nodes if node.is_leaf}\n",
    "        for tree_nodes in perp.get_node_lists()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(leaf_nodes, pred_nodes):\n",
    "    pred_weights = np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    leaf_nodes[i][key].weights\n",
    "                    for key in leaf_nodes[i].keys() & set(nodes)\n",
    "                ][0]\n",
    "                for nodes in tree_nodes\n",
    "            ]\n",
    "            for i, tree_nodes in enumerate(pred_nodes)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return np.sort(pred_weights, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Perpetual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_models = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "    perp = PerpetualBooster(budget=1.0, iteration_limit=10000)\n",
    "    perp.fit(X_train_cv, y_train_cv)\n",
    "    print(f\"Number of trees: {perp.number_of_trees}\")\n",
    "\n",
    "    perp_models.append(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "y_proba_perp = np.mean([m.predict_proba(X_test)[:, 1] for m in perp_models], axis=0)\n",
    "\n",
    "print(accuracy_score(y_test, np.rint(y_proba_perp)))\n",
    "print(f1_score(y_test, np.rint(y_proba_perp)))\n",
    "print(roc_auc_score(y_test, y_proba_perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_ece = np.mean([m.predict_proba(X_test)[:, 1] for m in perp_models], axis=0)\n",
    "print(expected_calibration_error(y_test, proba_ece, n_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_models[0].feature_importance_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.Series(\n",
    "    perp_models[0].feature_importances_, index=perp_models[0].feature_names_in_\n",
    ").sort_values(ascending=False)\n",
    "plt.figure(figsize=(8, 4))\n",
    "imp.iloc[::-1].plot(kind=\"barh\")\n",
    "plt.title(\"Feature Importance (PerpetualBooster)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights = get_weights(get_leaf_nodes(perp), perp.predict_nodes(X_test))\n",
    "pred_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights = get_weights(get_leaf_nodes(perp), perp.predict_nodes(X_test))\n",
    "pred_lower = np.sum(np.min(pred_weights, axis=2), axis=0) + perp.base_score\n",
    "pred_lower = 1.0 / (1.0 + np.exp(-pred_lower))\n",
    "pred_lower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights = get_weights(get_leaf_nodes(perp), perp.predict_nodes(X_test))\n",
    "pred_upper = np.sum(np.max(pred_weights, axis=2), axis=0) + perp.base_score\n",
    "pred_upper = 1.0 / (1.0 + np.exp(-pred_upper))\n",
    "pred_upper.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(pred_upper - pred_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(pred_lower, pred_upper, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(pred_upper - pred_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(\n",
    "    low=0, high=5, size=(pred_weights.shape[0], pred_weights.shape[1], n_simulations)\n",
    ")\n",
    "new_pred_weights = np.take_along_axis(pred_weights, indices, axis=2)\n",
    "print(f\"New array shape: {new_pred_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_weights_sum = np.sum(new_pred_weights, axis=0) + perp.base_score\n",
    "new_pred_weights_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_pred_weights_sum[:, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_weights_sum_proba = 1.0 / (1.0 + np.exp(-new_pred_weights_sum))\n",
    "new_pred_weights_sum_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_pred_weights_sum_proba[1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    np.max(new_pred_weights_sum_proba, axis=1)\n",
    "    - np.min(new_pred_weights_sum_proba, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_weights_sum_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_sim(m_sim, X_sim, n_sim=100):\n",
    "    pred_weights_sim = get_weights(get_leaf_nodes(m_sim), m_sim.predict_nodes(X_sim))\n",
    "    indices_sim = np.random.randint(\n",
    "        low=0,\n",
    "        high=5,\n",
    "        size=(pred_weights_sim.shape[0], pred_weights_sim.shape[1], n_sim),\n",
    "    )\n",
    "    new_pred_weights_sim = np.take_along_axis(pred_weights_sim, indices_sim, axis=2)\n",
    "    new_pred_weights_sum_sim = np.sum(new_pred_weights_sim, axis=0) + m_sim.base_score\n",
    "    new_pred_weights_sum_proba_sim = 1.0 / (1.0 + np.exp(-new_pred_weights_sum_sim))\n",
    "\n",
    "    return new_pred_weights_sum_proba_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_t(trial):\n",
    "    t = trial.suggest_float(\"threshold\", 0.0, 0.3)\n",
    "\n",
    "    profits = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        _X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        _y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        y_pred_sim = get_proba_sim(perp_models[i], X_test_cv, n_simulations)\n",
    "\n",
    "        profits_fold = []\n",
    "        for j in range(n_simulations):\n",
    "            profit, margin = business_objective(\n",
    "                y_test_cv.values, y_pred_sim[:, j], threshold=t\n",
    "            )\n",
    "            profits_fold.append(profit)\n",
    "\n",
    "    profits.append(profits_fold)\n",
    "\n",
    "    return np.mean(np.array(profits).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_t = optuna.samplers.TPESampler(seed=seed)\n",
    "study_t = optuna.create_study(direction=\"maximize\", sampler=sampler_t)\n",
    "study_t.optimize(objective_t, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_t.best_trial.params[\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean([m.predict_proba(X_test)[:, 1] for m in perp_models], axis=0)\n",
    "profit, margin = business_objective(\n",
    "    y_test.values, y_proba, threshold=study_t.best_trial.params[\"threshold\"]\n",
    ")\n",
    "print(f\"Profit: {profit}, Margin: {margin}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# Optimize threshold and weight index together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_weights = []\n",
    "for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "    pred_weights = get_weights(\n",
    "        get_leaf_nodes(perp_models[i]), perp_models[i].predict_nodes(X_test_cv)\n",
    "    )\n",
    "    model_pred_weights.append(pred_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_weights.shape = (n_trees, n_samples, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_from_weights(p_weights, w, b_score):\n",
    "    cal_weight, w_i_lower = math.modf(w)\n",
    "    w_i_lower = int(w_i_lower)\n",
    "    w_i_upper = w_i_lower + 1\n",
    "\n",
    "    weights_lower = np.sum(p_weights[:, :, w_i_lower], axis=0) + b_score\n",
    "    weights_upper = np.sum(p_weights[:, :, w_i_upper], axis=0) + b_score\n",
    "\n",
    "    weighted = weights_lower * (1 - cal_weight) + weights_upper * cal_weight\n",
    "\n",
    "    y_proba = 1.0 / (1.0 + np.exp(-weighted))\n",
    "\n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_w(trial):\n",
    "    t = trial.suggest_float(\"threshold\", 0.0, 0.3)\n",
    "    w = trial.suggest_float(\"weight_index\", 0.0, 4.0)\n",
    "\n",
    "    profits = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        _X_train_cv, _X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        _y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        y_proba = get_proba_from_weights(\n",
    "            model_pred_weights[i], w, perp_models[i].base_score\n",
    "        )\n",
    "\n",
    "        profit, margin = business_objective(\n",
    "            y_test_cv.values, y_proba, threshold=t, verbose=False\n",
    "        )\n",
    "\n",
    "    profits.append(profit)\n",
    "\n",
    "    return np.mean(profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_w = optuna.samplers.TPESampler(seed=seed)\n",
    "study_w = optuna.create_study(direction=\"maximize\", sampler=sampler_w)\n",
    "study_w.optimize(objective_w, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_w.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean(\n",
    "    [\n",
    "        get_proba_from_weights(\n",
    "            get_weights(get_leaf_nodes(m), m.predict_nodes(X_test)),\n",
    "            study_w.best_trial.params[\"weight_index\"],\n",
    "            m.base_score,\n",
    "        )\n",
    "        for m in perp_models\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "profit_w, margin_w = business_objective(\n",
    "    y_test.values,\n",
    "    y_proba,\n",
    "    threshold=study_w.best_trial.params[\"threshold\"],\n",
    "    verbose=False,\n",
    ")\n",
    "print(f\"Profit: {profit_w}, Margin: {margin_w}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# Optimize business objective with calibrated LightGBM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0\n",
    "best_profit = 0\n",
    "\n",
    "for t in np.arange(0.01, 0.5, 0.01):\n",
    "    profits = []\n",
    "    margins = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        m = lgbm_cal_classifiers[i]\n",
    "        y_proba = m.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "        profit, margin = business_objective(\n",
    "            y_test_cv.values, y_proba, threshold=t, verbose=False\n",
    "        )\n",
    "        profits.append(profit)\n",
    "        margins.append(margin)\n",
    "\n",
    "    if np.mean(profits) >= best_profit:\n",
    "        best_profit = np.mean(profits)\n",
    "        best_threshold = t\n",
    "\n",
    "    print(\n",
    "        f\"Threshold: {t:.3f}, Profit: {np.mean(profits):.0f}, Margin: {np.mean(margins):.2f}%\"\n",
    "    )\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.3f}, Best profit: {best_profit:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean([m.predict_proba(X_test)[:, 1] for m in lgbm_cal_classifiers], axis=0)\n",
    "profit_l, margin_l = business_objective(\n",
    "    y_test.values, y_proba, threshold=best_threshold, verbose=False\n",
    ")\n",
    "print(f\"Profit: {profit_l}, Margin: {margin_l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.01, 0.5, 0.01):\n",
    "    y_proba = np.mean(\n",
    "        [m.predict_proba(X_test)[:, 1] for m in lgbm_cal_classifiers], axis=0\n",
    "    )\n",
    "    profit_l_test, margin_l_test = business_objective(\n",
    "        y_test.values, y_proba, threshold=t, verbose=False\n",
    "    )\n",
    "    print(f\"Threshold: {t:.2f}, Profit: {profit_l_test}, Margin: {margin_l_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((profit_w - profit_l) / abs(profit_l)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "# Optimize threshold, weight index, budget together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_list = [0.1, 0.2, 0.3, 0.5, 1.0, 1.5, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_models = []\n",
    "model_pred_weights = []\n",
    "for budget in budget_list:\n",
    "    cv_pred_weights = []\n",
    "    p_models_cv = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_train_cv, X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "        m = PerpetualBooster(budget=budget, iteration_limit=10000)\n",
    "        m.fit(X_train_cv, y_train_cv)\n",
    "        pred_weights = get_weights(get_leaf_nodes(m), m.predict_nodes(X_test_cv))\n",
    "        cv_pred_weights.append(pred_weights)\n",
    "        p_models_cv.append(m)\n",
    "        print(f\"Budget: {budget}, Fold: {i}, Number of trees: {m.number_of_trees}\")\n",
    "    print()\n",
    "    p_models.append(p_models_cv)\n",
    "    model_pred_weights.append(cv_pred_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_index_min = 0\n",
    "for i, b in enumerate(budget_list):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    cv_models_prev = p_models[i - 1]\n",
    "    cv_models = p_models[i]\n",
    "    min_diff_n_trees = min(\n",
    "        [\n",
    "            cv_models[j].number_of_trees - cv_models_prev[j].number_of_trees\n",
    "            for j in range(len(cv_models))\n",
    "        ]\n",
    "    )\n",
    "    if min_diff_n_trees < 0:\n",
    "        budget_index_min = i\n",
    "    print(\n",
    "        f\"i: {i}, budget: {b}, previous budget n_trees: {[cv_models_prev[j].number_of_trees for j in range(len(cv_models_prev))]}, current budget n_trees: {[cv_models[j].number_of_trees for j in range(len(cv_models))]}, min_diff_n_trees: {min_diff_n_trees}\"\n",
    "    )\n",
    "\n",
    "print(f\"Minimum budget index without tree count regression: {budget_index_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_b(trial):\n",
    "    t = trial.suggest_float(\"threshold\", 0.0, 0.3)\n",
    "    w = trial.suggest_float(\"weight_index\", 0.0, 4.0)\n",
    "    b = trial.suggest_categorical(\n",
    "        \"budget_index\", list(range(budget_index_min, len(budget_list), 1))\n",
    "    )\n",
    "\n",
    "    profits = []\n",
    "    for i, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "        _X_train_cv, _X_test_cv = X_train.iloc[train], X_train.iloc[test]\n",
    "        _y_train_cv, y_test_cv = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        y_proba = get_proba_from_weights(\n",
    "            model_pred_weights[b][i], w, p_models[b][i].base_score\n",
    "        )\n",
    "\n",
    "        profit, margin = business_objective(\n",
    "            y_test_cv.values, y_proba, threshold=t, verbose=False\n",
    "        )\n",
    "\n",
    "    profits.append(profit)\n",
    "\n",
    "    return np.mean(profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_b = optuna.samplers.TPESampler(seed=seed)\n",
    "study_b = optuna.create_study(direction=\"maximize\", sampler=sampler_b)\n",
    "study_b.optimize(objective_b, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_b.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_list[study_b.best_trial.params[\"budget_index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean(\n",
    "    [\n",
    "        get_proba_from_weights(\n",
    "            get_weights(get_leaf_nodes(m), m.predict_nodes(X_test)),\n",
    "            study_b.best_trial.params[\"weight_index\"],\n",
    "            m.base_score,\n",
    "        )\n",
    "        for m in p_models[study_b.best_trial.params[\"budget_index\"]]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "profit_b, margin_b = business_objective(\n",
    "    y_test.values,\n",
    "    y_proba,\n",
    "    threshold=study_b.best_trial.params[\"threshold\"],\n",
    "    verbose=False,\n",
    ")\n",
    "print(f\"Profit: {profit_b}, Margin: {margin_b}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.mean(\n",
    "    [\n",
    "        get_proba_from_weights(\n",
    "            get_weights(get_leaf_nodes(m), m.predict_nodes(X_test)),\n",
    "            study_b.best_trial.params[\"weight_index\"],\n",
    "            m.base_score,\n",
    "        )\n",
    "        for m in p_models[study_b.best_trial.params[\"budget_index\"]]\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "for t in np.arange(0.01, 0.5, 0.01):\n",
    "    profit_b_test, margin_b_test = business_objective(\n",
    "        y_test.values, y_proba, threshold=t, verbose=False\n",
    "    )\n",
    "    print(f\"Threshold: {t:.2f}, Profit: {profit_b_test}, Margin: {margin_b_test}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((profit_b - profit_l) / abs(profit_l)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM n_estimators = 100\n",
    "# 0.1 -> 1010250 -> -4.05428401259253\n",
    "# 0.2 -> 989250  -> -2.7184548625882754\n",
    "# 0.3 -> 987000  -> -8.580787883944526\n",
    "# 0.5 -> 1135000 -> -4.479707308772228\n",
    "# 1.0 -> 1046250 -> -0.22547434697524038\n",
    "# 1.5 -> 1052000 -> 1.3060495192716752\n",
    "# 2.0 -> 1073500 -> 1.9016421339232537\n",
    "# 2.5 -> 1072500 -> -0.6041010805751723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM n_estimators = 1000\n",
    "# 2.0 -> 1074250 -> 1.131326776140825"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forust-main-perp-oss (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
