{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Instrumental Variables (Boosted IV)\n",
    "\n",
    "Instrumental variables (IV) are a powerful tool in causal inference for estimating causal effects when there is unobserved confounding between the treatment $W$ and the outcome $Y$.\n",
    "\n",
    "In this tutorial, we will use the **Card (1995)** dataset to estimate the causal effect of education on earnings. The problem is that factors like \"ability\" are unobserved and affect both education levels and earnings (confounding). Card proposed using \"proximity to college\" as an **instrument** ($Z$), assuming it affects education but has no direct effect on earnings.\n",
    "\n",
    "Perpetual's `BraidedBooster` implements a boosted **Control Function** approach, which avoids the biased \"Forbidden Regression\" often found in naive boosted IV implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from perpetual import PerpetualBooster\n",
    "from perpetual.iv import BraidedBooster\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset\n",
    "\n",
    "We fetch the Wine Quality dataset from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching 'wine-quality' dataset for IV demo...\")\n",
    "# Use the 'wine-quality' dataset as a more realistic stand-in for IV demonstration\n",
    "data = fetch_openml(name=\"wine-quality-red\", as_frame=True, parser=\"auto\")\n",
    "df = data.frame\n",
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for wine-quality IV demo\n",
    "# We'll treat 'class' as the outcome, 'alcohol' as treatment, 'sulphates' as instrument, and the rest as covariates\n",
    "\n",
    "y = df[\"class\"].values  # Outcome: Wine quality score\n",
    "w = df[\"alcohol\"].values  # Treatment: Alcohol content\n",
    "z = df[\"sulphates\"].values  # Instrument: Sulphates\n",
    "\n",
    "# Covariates (all except outcome, treatment, instrument)\n",
    "covariates = [\n",
    "    \"fixed_acidity\",\n",
    "    \"volatile_acidity\",\n",
    "    \"citric_acid\",\n",
    "    \"residual_sugar\",\n",
    "    \"chlorides\",\n",
    "    \"free_sulfur_dioxide\",\n",
    "    \"total_sulfur_dioxide\",\n",
    "    \"density\",\n",
    "    \"pH\",\n",
    "]\n",
    "X = df[covariates].copy()\n",
    "\n",
    "X_train, X_test, z_train, z_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, z, y, w, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Naive Model vs. IV Model\n",
    "\n",
    "First, let's see why a naive model might be biased. We'll fit a standard `PerpetualBooster` on $X$ and $W$ directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = PerpetualBooster(budget=0.1)\n",
    "# Combine X and W for naive fit\n",
    "X_naive = np.column_stack([X_train, w_train])\n",
    "naive.fit(X_naive, y_train)\n",
    "\n",
    "# Estimate effect: Average change in y if alcohol increases by 1 unit\n",
    "X_test_base = np.column_stack([X_test, w_test.astype(float)])\n",
    "X_test_plus = np.column_stack([X_test, (w_test.astype(float) + 1)])\n",
    "# Ensure predictions are float for subtraction\n",
    "pred_base = naive.predict(X_test_base).astype(float)\n",
    "pred_plus = naive.predict(X_test_plus).astype(float)\n",
    "naive_effect = (pred_plus - pred_base).mean()\n",
    "print(f\"Naive estimated effect of 1 unit alcohol: {naive_effect:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 3. BraidedBooster (IV)\n",
    "\n",
    "The `BraidedBooster` uses the instrument to find the variation in education that is uncorrelated with the unobserved confounders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit IV model\n",
    "iv_model = BraidedBooster(stage1_budget=0.1, stage2_budget=0.1)\n",
    "\n",
    "# X: covariates, Z: instruments, y: outcome, w: treatment\n",
    "# Z can be a matrix if you have multiple instruments\n",
    "Z_train = z_train.reshape(-1, 1)\n",
    "Z_test = z_test.reshape(-1, 1)\n",
    "\n",
    "iv_model.fit(X_train, Z_train, y_train, w_train)\n",
    "\n",
    "# Predict causal effect\n",
    "# We compare counterfactual predictions at w and w+1\n",
    "y_pred_base = iv_model.predict(X_test, w_counterfactual=w_test)\n",
    "y_pred_plus = iv_model.predict(X_test, w_counterfactual=w_test + 1)\n",
    "causal_effect = (y_pred_plus - y_pred_base).mean()\n",
    "\n",
    "print(f\"IV estimated causal effect of 1 unit alcohol: {causal_effect:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 3.1 Advanced: Interaction Constraints\n",
    "\n",
    "Just like the base booster, `BraidedBooster` supports interaction constraints. This can be crucial in IV models to prevent the stage 2 model from leveraging spurious interactions between covariates and the predicted treatment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Allow only 'exper' (0) and 'black' (2) to interact\n",
    "interaction_constraints = [[0, 2]]\n",
    "iv_constrained = BraidedBooster(\n",
    "    stage1_budget=0.1,\n",
    "    stage2_budget=0.1,\n",
    "    interaction_constraints=interaction_constraints,\n",
    ")\n",
    "iv_constrained.fit(X_train, Z_train.reshape(-1, 1), y_train, w_train)\n",
    "iv_effect_constrained = (\n",
    "    iv_constrained.predict(X_test, w_test + 1) - iv_constrained.predict(X_test, w_test)\n",
    ").mean()\n",
    "print(f\"Constrained IV effect: {iv_effect_constrained:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "If the IV estimate is significantly different from the naive estimate, it suggests the presence of endogeneity (confounding). In many economic studies, the IV estimate for education is actually higher than the OLS/Naive estimate, suggesting that those who are most affected by the instrument (proximity) might have higher returns to schooling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
